{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair_ally as aly\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "aly.alt.data_transformers.enable('vegafusion')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501bb7a",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "---\n",
    "We built a classification model using both the Logistic Regression and Support Vector Classifier (SVC) which can use the information related to the client and the marketing contact to predict whether a client will subscribe to a term deposit.\n",
    "\n",
    "Our final classifier, the Logistic Regression model, performed well on an unseen test data set, achieving a Test Score (Accuracy) of **0.90375** (compared to **0.90125** for SVC). The Train Score was 0.905625, indicating a good fit without significant overfitting. Although the simple accuracy score does not detail the balance of True Positives versus False Negatives, an accuracy exceeding **90%** suggests the model is highly effective.\n",
    "\n",
    "Given our goal is to increase the subscription rate, the model's primary goal is to minimize the False Negative rate, avoiding the error of predicting a client will not subscribe when they would have. The current performance suggests that using this model for initial client prioritization could significantly improve resource allocation, making the model valuable for immediate business implementation. However, further analysis of precision and recall would be necessary to optimize its practical utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bdb6f8",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "---\n",
    "Direct marketing campaigns, particularly those relying on phone calls, are a significant investment for banking institutions. The success of these campaigns is measured by the client subscription rate to a product like a term deposit. Another dataset shows that the subscription rate of term deposit in a Portuguese banking is only around 11.70% [Ngu Hui En 2024](https://medium.com/@nguhe/predictive-analysis-of-client-subscription-rates-in-the-portuguese-banking-sector-using-sas-40fb04a9dcd3), optimizing the targeting strategy is crucial to maximize return on investment and minimize operational costs.\n",
    "\n",
    "Here we ask if a machine learning algorithm can be used to predict whether a client will subscribe to a term deposit based on information related to the client, such as type of job, education level; and also the marketing contact, e.g. number of contacts during the campaign, number of days since last contact. Answering this question is important because term deposit campaigns often require multiple contacts to the same client, making the process labor-intensive and expensive. Thus, if a machine learning algorithm can accurately and effectively predict client subscription, this could allow the bank to prioritize clients who are most likely to convert, leading to more efficient resource allocation and a higher overall subscription rate, improving the campaign results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004adc4",
   "metadata": {},
   "source": [
    "# Methods:\n",
    "---\n",
    "\n",
    "## Data: \n",
    "The data we used was obtained the UCI Machine Learning Repository which can be found [here](https://doi.org/10.24432/C5K306), specifically the Bank Marketing dataset of a Portuguese bank institution . The dataset contains various features about bank customers and whether they subscribed to a term deposit, an investment product offered by the bank (variable y). Each row in the dataset contains details of customers which was used to predict if they would subscribe to the term deposit or not. The original dataset contains 45211 records with 16 features and one target (17 columns). For the purpose of this analysis, we sampled 4,000 records from the original dataset to speed up the EDA and model training process.\n",
    "\n",
    "\n",
    "## Analysis: \n",
    "We started this analysis by perfoming an exploratory data analysis (EDA) to understand the nature of the variables and their relationships. We observed some missing values in the dataset. We also observed that the target variable (y) was imbalanced with a higher proportion of customers not subscribing to the term deposit. \n",
    "\n",
    "Furthermore, distribution plots for variables previous, pday, campaign, duration, balance were highly right-skewed. This implies that most customers had low values for these varaibles and a few customers had high values. In addition, the correlation plots in Figure 3 showed that \"previous\" and \"pday\" had the highest positive correlation.\n",
    "\n",
    "We decided to use both Logistic Regression and Support Vector Classifier (SVC) models for this analysis.The [sklearn](https://scikit-learn.org/stable/) package was greatly used in these processes. We performed hyperparameter tuning using Python RandomizedSearchCV to find the best parameters for each model. We mapped the values of the target y, using 'yes': 1, 'no': 0. The data was split using 80% for the training set and 20% for the test set. In the preprocessing, we dropped 'day_of_week' and 'pdays' because we considered them not relevant for analysis. The 'poutcome' variable was also dropped since it had a high number of missing values. Categorical variables were one-hot encoded, ordinal data were handled using ordinal encoding, numerical variables were scaled using StandardScaler and missing values for the selected features were imputed using SimpleImputer with the \"most frequent\" strategy.\n",
    "\n",
    "The models were evaluated based on their accuracy on the test set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77281ea",
   "metadata": {},
   "source": [
    "### Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download Data -- NEEDS ATTRIBUTION FOR DOWNLOAD CODE from UCI ML github repo\n",
    "\n",
    "## Uncomment and Run to install neccessary packages\n",
    "#!pip3 install -U ucimlrepo \n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = bank_marketing.data.features \n",
    "y = bank_marketing.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(bank_marketing.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(bank_marketing.variables) \n",
    "\n",
    "bank_marketing_data =X; bank_marketing_data['y'] = y\n",
    "#bank_marketing_data.to_csv('data/bank_marketing.csv')\n",
    "\n",
    "bank_marketing_sample = bank_marketing_data.sample(4000, random_state=522)\n",
    "#bank_marketing_sample.to_csv('data/bank_marketing_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe71353",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f87179",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing.data.features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bece638",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing.data.targets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_plot = aly.dist(bank_marketing_sample, color='y')\n",
    "\n",
    "numeric_plot.properties(\n",
    "    title=\"Figure 1: Univariate distributions of numeric variables in Bank Marketing Dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate distrbutions (counts) for the categorical variables\n",
    "\n",
    "categorical_plots = aly.dist(\n",
    "    bank_marketing_sample, dtype='object', color='y')\n",
    "\n",
    "categorical_plots.properties(\n",
    "    title=\"Figure 2: Univariate distributions of category variables in Bank Marketing Dataset\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plots = aly.corr(bank_marketing_sample)\n",
    "correlation_plots.properties(\n",
    "    title=\"Figure 3: Correlation Plots For Numeric variables in Bank Marketing Dataset\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7a22b",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_sample.isnull().sum() / bank_marketing_sample.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b97917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "#bank_marketing_sample = bank_marketing_sample.copy()\n",
    "\n",
    "# map the target variable to numeric\n",
    "bank_marketing_sample['y'] = bank_marketing_sample['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "\n",
    "# feature engineering on 'pdays' column into categorical determining if client was contacted before or not\n",
    "bank_marketing_sample['pdays_contacted'] = bank_marketing_sample['pdays'].apply(lambda x: 'never' if x == -1 else 'contacted')\n",
    "\n",
    "# dropping columns\n",
    "bank_marketing_sample= bank_marketing_sample.drop(columns=['day_of_week', 'pdays', 'poutcome'])\n",
    "\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(bank_marketing_sample.drop(columns='y'), bank_marketing_sample['y'], test_size=0.2, random_state=522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.select_dtypes(include=['object']).nunique()\n",
    "\n",
    "bank_marketing_sample.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_sample.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bcfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating columns by type of transformation required\n",
    "\n",
    "# One-hot encoding\n",
    "categorical_cols = ['job', 'marital', 'default', 'housing', 'loan', 'contact','month', 'pdays_contacted']\n",
    "# Ordinal encoding\n",
    "ordinal_cols = ['education']\n",
    "# Standard scaling\n",
    "numerical_cols = ['age', 'balance', 'duration', 'campaign', 'previous']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18caafee",
   "metadata": {},
   "source": [
    "We decided to train both a Logistic Regression and Support Vector Classifier (SVC) to determine which was more efficient in predicting if a customer would subscribed to the banks offering of term investments. We performed hyperparameter tuning using RandomizedSearchCV to find the best parameters for each model. The models were evaluated based on their accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the preprocessor\n",
    "\n",
    "data_preprocessor = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown='ignore')), categorical_cols\n",
    "    ), (\n",
    "        make_pipeline(SimpleImputer(strategy='most_frequent'), OrdinalEncoder(categories=[['unknown', 'primary', 'secondary', 'tertiary']], dtype=object)), ordinal_cols\n",
    "    ), (StandardScaler(), numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc722ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression cross-validation with RandomizedSearchCV \n",
    "lr_pipe = make_pipeline(data_preprocessor, LogisticRegression(random_state=42, max_iter=1000))\n",
    "param_dist1 = {\"logisticregression__C\": loguniform(1e-4, 1e3)} \n",
    "random_lr = RandomizedSearchCV(lr_pipe, param_distributions=param_dist1,\n",
    "                                n_iter=100, n_jobs=-1, return_train_score=True, random_state=522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b328aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "random_lr.fit(X_train, y_train)\n",
    "print(f'Train Score: {random_lr.score(X_train, y_train)}')\n",
    "print(f'Test Score: {random_lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC cross-validation with RandomizedSearchCV \n",
    "svc_pipe = make_pipeline(data_preprocessor, SVC(random_state=42))\n",
    "param_dist = { \"svc__C\": loguniform(1e-2, 1e3), \"svc__gamma\": loguniform(1e-2, 1e3)}\n",
    "random_svc = RandomizedSearchCV(svc_pipe, param_distributions=param_dist,\n",
    "                                n_iter=100, n_jobs=-1, return_train_score=True, random_state=522)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22982c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "random_svc.fit(X_train, y_train)\n",
    "print(f'Train Score: {random_svc.score(X_train, y_train)}')\n",
    "print(f'Test Score: {random_svc.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f87131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for Logistic Regression model\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    random_lr,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    values_format=\"d\",\n",
    ");\n",
    "plt.title(\"Figure 4: Confusion Matrix for Logistic Regression model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for SVC model\n",
    "\n",
    "y = ConfusionMatrixDisplay.from_estimator(\n",
    "    random_svc,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    values_format=\"d\",\n",
    ");\n",
    "plt.title(\"Figure 5: Confusion Matrix for SVC model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63faf2e",
   "metadata": {},
   "source": [
    "# Results & Discussion\n",
    "---\n",
    "\n",
    "Both our Logistic Regression and SVC classification models performed well on the testing data, with final scores of 0.90375 and 0.90125, respectively. Further comparison shows that the testing scores are similar to the training scores of 0.905625 and 0.919375, indicating that our models are well-fitted.\n",
    "\n",
    "Considering the imbalance in our target class, accuracy alone is not sufficient for determining the suitability of our model. Therefore, exploring metrics from the confusion matrix and classification report is recommended as a next step.\n",
    "\n",
    "A second area for further analysis is determining which specific features are most important for predicting whether a client will subscribe to a term deposit. Identifying these key features will enable the bank to better tailor its actions to increase subscription rates. In light of this, the Logistic Regression model is a better choice, as it provides more interpretable results. However, due to interactions between features and preprocessing steps such as regularization, the coefficients of the Logistic Regression model can become difficult to interpret. Nevertheless, if properly examined, the coefficient estimates can help identify the important characteristics the bank should focus on to increase its rate of subscriptions to term deposits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b65f27",
   "metadata": {},
   "source": [
    "## References:\n",
    "---\n",
    "<br> Ngu, H. E. (2024). Predictive analysis of client subscription rates in the Portuguese banking sector using SAS. Medium. https://medium.com/@nguhe/predictive-analysis-of-client-subscription-rates-in-the-portuguese-banking-sector-using-sas-40fb04a9dcd3 <br>\n",
    "<br>Timbers, T. (n.d.). breast_cancer_predictor (Version 0.0.1) [Computer software]. GitHub. https://github.com/ttimbers/breast_cancer_predictor/tree/0.0.1<br>\n",
    "<br>Moro, S., Rita, P., & Cortez, P. (2014). Bank Marketing [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5K306. <br>\n",
    "<br>Scikit-learn. (n.d.). scikit-learn: Machine learning in Python. Retrieved November 21, 2025, from https://scikit-learn.org/stable/<br>\n",
    "<br>uci-ml-repo (2025). ucimlrepo: Python package for dataset imports from the UCI Machine Learning Repository [Computer software]. GitHub. https://github.com/uci-ml-repo/ucimlrepo<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term-deposit-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
